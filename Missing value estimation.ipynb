{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T15:34:34.194860Z",
     "start_time": "2024-03-31T15:34:33.453722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  checking_status  duration                     credit_history  \\\n0           b'<0'       6.0  b'critical/other existing credit'   \n1     b'0<=X<200'      48.0                   b'existing paid'   \n2  b'no checking'      12.0  b'critical/other existing credit'   \n3           b'<0'      42.0                   b'existing paid'   \n4           b'<0'      24.0              b'delayed previously'   \n\n                  purpose  credit_amount       savings_status employment  \\\n0             b'radio/tv'         1169.0  b'no known savings'     b'>=7'   \n1             b'radio/tv'         5951.0              b'<100'  b'1<=X<4'   \n2            b'education'         2096.0              b'<100'  b'4<=X<7'   \n3  b'furniture/equipment'         7882.0              b'<100'  b'4<=X<7'   \n4              b'new car'         4870.0              b'<100'  b'1<=X<4'   \n\n   installment_commitment        personal_status other_parties  ...  \\\n0                     4.0         b'male single'       b'none'  ...   \n1                     2.0  b'female div/dep/mar'       b'none'  ...   \n2                     2.0         b'male single'       b'none'  ...   \n3                     2.0         b'male single'  b'guarantor'  ...   \n4                     3.0         b'male single'       b'none'  ...   \n\n     property_magnitude   age  other_payment_plans      housing  \\\n0        b'real estate'  67.0              b'none'       b'own'   \n1        b'real estate'  22.0              b'none'       b'own'   \n2        b'real estate'  49.0              b'none'       b'own'   \n3     b'life insurance'  45.0              b'none'  b'for free'   \n4  b'no known property'  53.0              b'none'  b'for free'   \n\n  existing_credits                    job num_dependents  own_telephone  \\\n0              2.0             b'skilled'            1.0         b'yes'   \n1              1.0             b'skilled'            1.0        b'none'   \n2              1.0  b'unskilled resident'            2.0        b'none'   \n3              1.0             b'skilled'            2.0        b'none'   \n4              2.0             b'skilled'            2.0        b'none'   \n\n  foreign_worker    class  \n0         b'yes'  b'good'  \n1         b'yes'   b'bad'  \n2         b'yes'  b'good'  \n3         b'yes'  b'good'  \n4         b'yes'   b'bad'  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>checking_status</th>\n      <th>duration</th>\n      <th>credit_history</th>\n      <th>purpose</th>\n      <th>credit_amount</th>\n      <th>savings_status</th>\n      <th>employment</th>\n      <th>installment_commitment</th>\n      <th>personal_status</th>\n      <th>other_parties</th>\n      <th>...</th>\n      <th>property_magnitude</th>\n      <th>age</th>\n      <th>other_payment_plans</th>\n      <th>housing</th>\n      <th>existing_credits</th>\n      <th>job</th>\n      <th>num_dependents</th>\n      <th>own_telephone</th>\n      <th>foreign_worker</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b'&lt;0'</td>\n      <td>6.0</td>\n      <td>b'critical/other existing credit'</td>\n      <td>b'radio/tv'</td>\n      <td>1169.0</td>\n      <td>b'no known savings'</td>\n      <td>b'&gt;=7'</td>\n      <td>4.0</td>\n      <td>b'male single'</td>\n      <td>b'none'</td>\n      <td>...</td>\n      <td>b'real estate'</td>\n      <td>67.0</td>\n      <td>b'none'</td>\n      <td>b'own'</td>\n      <td>2.0</td>\n      <td>b'skilled'</td>\n      <td>1.0</td>\n      <td>b'yes'</td>\n      <td>b'yes'</td>\n      <td>b'good'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b'0&lt;=X&lt;200'</td>\n      <td>48.0</td>\n      <td>b'existing paid'</td>\n      <td>b'radio/tv'</td>\n      <td>5951.0</td>\n      <td>b'&lt;100'</td>\n      <td>b'1&lt;=X&lt;4'</td>\n      <td>2.0</td>\n      <td>b'female div/dep/mar'</td>\n      <td>b'none'</td>\n      <td>...</td>\n      <td>b'real estate'</td>\n      <td>22.0</td>\n      <td>b'none'</td>\n      <td>b'own'</td>\n      <td>1.0</td>\n      <td>b'skilled'</td>\n      <td>1.0</td>\n      <td>b'none'</td>\n      <td>b'yes'</td>\n      <td>b'bad'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b'no checking'</td>\n      <td>12.0</td>\n      <td>b'critical/other existing credit'</td>\n      <td>b'education'</td>\n      <td>2096.0</td>\n      <td>b'&lt;100'</td>\n      <td>b'4&lt;=X&lt;7'</td>\n      <td>2.0</td>\n      <td>b'male single'</td>\n      <td>b'none'</td>\n      <td>...</td>\n      <td>b'real estate'</td>\n      <td>49.0</td>\n      <td>b'none'</td>\n      <td>b'own'</td>\n      <td>1.0</td>\n      <td>b'unskilled resident'</td>\n      <td>2.0</td>\n      <td>b'none'</td>\n      <td>b'yes'</td>\n      <td>b'good'</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b'&lt;0'</td>\n      <td>42.0</td>\n      <td>b'existing paid'</td>\n      <td>b'furniture/equipment'</td>\n      <td>7882.0</td>\n      <td>b'&lt;100'</td>\n      <td>b'4&lt;=X&lt;7'</td>\n      <td>2.0</td>\n      <td>b'male single'</td>\n      <td>b'guarantor'</td>\n      <td>...</td>\n      <td>b'life insurance'</td>\n      <td>45.0</td>\n      <td>b'none'</td>\n      <td>b'for free'</td>\n      <td>1.0</td>\n      <td>b'skilled'</td>\n      <td>2.0</td>\n      <td>b'none'</td>\n      <td>b'yes'</td>\n      <td>b'good'</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b'&lt;0'</td>\n      <td>24.0</td>\n      <td>b'delayed previously'</td>\n      <td>b'new car'</td>\n      <td>4870.0</td>\n      <td>b'&lt;100'</td>\n      <td>b'1&lt;=X&lt;4'</td>\n      <td>3.0</td>\n      <td>b'male single'</td>\n      <td>b'none'</td>\n      <td>...</td>\n      <td>b'no known property'</td>\n      <td>53.0</td>\n      <td>b'none'</td>\n      <td>b'for free'</td>\n      <td>2.0</td>\n      <td>b'skilled'</td>\n      <td>2.0</td>\n      <td>b'none'</td>\n      <td>b'yes'</td>\n      <td>b'bad'</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "# Load data\n",
    "raw_data = loadarff(\"dataset_31_credit-g.arff\")\n",
    "df = pd.DataFrame(raw_data[0])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Some columns are of data type \"byte\" --> convert them to strings\n",
    "for col, dtype in df.dtypes.items():\n",
    "    if dtype == object:  # Only process byte object columns.\n",
    "        df[col] = df[col].apply(lambda x: x.decode(\"utf-8\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T15:34:34.210374Z",
     "start_time": "2024-03-31T15:34:34.196362Z"
    }
   },
   "id": "d2884cfd1fd2883",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set missing values:\n",
    "# - \"no known savings\" of variable \"savings_status\"\n",
    "# - \"no known property\" of variable \"property_magnitude\"\n",
    "\n",
    "df[\"savings_status\"] = df[\"savings_status\"].replace({\"no known savings\": None})\n",
    "df[\"property_magnitude\"] = df[\"property_magnitude\"].replace({\"no known property\": None})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T15:34:34.225887Z",
     "start_time": "2024-03-31T15:34:34.211374Z"
    }
   },
   "id": "9ce4d266b5d3e247",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savings_status\n",
      "<100           603\n",
      "100<=X<500     103\n",
      "500<=X<1000     63\n",
      ">=1000          48\n",
      "Name: count, dtype: int64\n",
      "183 missing values\n",
      "\n",
      "property_magnitude\n",
      "car               332\n",
      "real estate       282\n",
      "life insurance    232\n",
      "Name: count, dtype: int64\n",
      "154 missing values\n"
     ]
    }
   ],
   "source": [
    "incomplete_variables = df.columns[df.isna().sum() > 0]\n",
    "complete_variables = df.columns.drop(incomplete_variables)\n",
    "\n",
    "# Investigate distribution of incomplete variables\n",
    "for var in incomplete_variables:\n",
    "    print(df[var].value_counts())\n",
    "    print(f\"{df[var].isna().sum()} missing values\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T15:34:34.241400Z",
     "start_time": "2024-03-31T15:34:34.226888Z"
    }
   },
   "id": "bea6c3f0da35921b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savings_status:\n",
      "- 0.000 checking_status\n",
      "- 0.001 other_parties\n",
      "- 0.000 class\n",
      "property_magnitude:\n",
      "- 0.000 duration\n",
      "- 0.000 purpose\n",
      "- 0.000 credit_amount\n",
      "- 0.016 employment\n",
      "- 0.000 other_parties\n",
      "- 0.000 job\n",
      "- 0.000 own_telephone\n",
      "- 0.000 foreign_worker\n",
      "- 0.014 class\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency, kruskal\n",
    "\n",
    "# Identify which complete variables have a dependency relationship with which incomplete variables\n",
    "alpha = .05\n",
    "dependent_variables = {}\n",
    "for var1 in incomplete_variables:\n",
    "    dependent_variables[var1] = []\n",
    "    \n",
    "    print(f\"{var1}:\")\n",
    "    for var2 in complete_variables:\n",
    "        if df[var2].dtype == \"object\":\n",
    "            # G-Test\n",
    "            observed = pd.crosstab(df[var1], df[var2])\n",
    "            _, p, _, _ = chi2_contingency(observed, lambda_=\"log-likelihood\")\n",
    "        else:\n",
    "            # Kruskal-Wallis Test\n",
    "            samples = []\n",
    "            for value in df[var1].unique():\n",
    "                if value is None:\n",
    "                    continue\n",
    "                \n",
    "                samples.append(df[var2][df[var1] == value])\n",
    "            \n",
    "            _, p = kruskal(*samples)\n",
    "\n",
    "        if p < alpha:\n",
    "            dependent_variables[var1].append(var2)\n",
    "            print(f\"- {p:.3f} {var2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T15:34:34.986040Z",
     "start_time": "2024-03-31T15:34:34.242901Z"
    }
   },
   "id": "304443ac385a782c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savings_status\n",
      "- Train: 0.368 Â± 0.030\n",
      "- Test: 0.323 Â± 0.029\n",
      "property_magnitude\n",
      "- Train: 0.633 Â± 0.005\n",
      "- Test: 0.477 Â± 0.025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Missing value estimation\n",
    "\n",
    "\n",
    "def one_hot_encode(data):\n",
    "    ohe_data = data.copy()\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            dummy_columns = pd.get_dummies(data[col], prefix=col, drop_first=(data[col].nunique() == 2))\n",
    "            ohe_data = pd.concat([ohe_data, dummy_columns], axis=1)\n",
    "            ohe_data = ohe_data.drop(col, axis=1)\n",
    "    \n",
    "    return ohe_data\n",
    "\n",
    "\n",
    "random_state = 20 # TODO: set to \"None\" after optimization\n",
    "for var in incomplete_variables:\n",
    "    X = one_hot_encode(df[dependent_variables[var]])\n",
    "    \n",
    "    # Drop instances from X for which var is missing\n",
    "    y = df[var][~df[var].isna()]\n",
    "    X = X.iloc[y.index]\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(shuffle=True, random_state=random_state)\n",
    "    scores = {\"train\": [], \"test\": []}\n",
    "    \n",
    "    # Determine class and sample weights\n",
    "    class_frequencies = y.value_counts()\n",
    "    classes = class_frequencies.index.tolist()\n",
    "    class_weights = {classes[0]: 1}\n",
    "    for c in classes[1:]:\n",
    "        class_weights[c] = class_frequencies.iloc[0] / class_frequencies.loc[c]\n",
    "    \n",
    "    sample_weights = y.apply(lambda x: class_weights[x])\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        # Train/test split\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        w_train = sample_weights.iloc[train_idx]\n",
    "        \n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "        w_test = sample_weights.iloc[test_idx]\n",
    "        \n",
    "        # Train a classifier w/ sample weights\n",
    "        clf = RandomForestClassifier(max_depth=5, random_state=random_state).fit(X_train, y_train, sample_weight=w_train)\n",
    "        \n",
    "        # Evaluate the classifier using f1-score w/ sample weights\n",
    "        scores[\"train\"].append(f1_score(y_train, clf.predict(X_train), average=\"macro\", sample_weight=w_train))\n",
    "        scores[\"test\"].append(f1_score(y_test, clf.predict(X_test), average=\"macro\", sample_weight=w_test))\n",
    "    \n",
    "    print(var)\n",
    "    print(f\"- Train: {np.mean(scores['train']):.3f} Â± {np.std(scores['train']):.3f}\")\n",
    "    print(f\"- Test: {np.mean(scores['test']):.3f} Â± {np.std(scores['test']):.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T15:34:36.444294Z",
     "start_time": "2024-03-31T15:34:34.987041Z"
    }
   },
   "id": "e2f9cef9c6449bc3",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T15:34:36.459808Z",
     "start_time": "2024-03-31T15:34:36.445295Z"
    }
   },
   "id": "b988ca6bca116174",
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
